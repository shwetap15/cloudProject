<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_z5vjwkd6ap1-8>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-8,lower-roman) ". "}.lst-kix_z5vjwkd6ap1-7>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-7,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-5>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-5,lower-roman) ". "}.lst-kix_z5vjwkd6ap1-4>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-4,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-6>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-6,decimal) ". "}ol.lst-kix_z5vjwkd6ap1-7.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-7 0}.lst-kix_z5vjwkd6ap1-1>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-1,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-4>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-4}.lst-kix_z5vjwkd6ap1-0>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-0,decimal) ". "}.lst-kix_z5vjwkd6ap1-2>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-2,lower-roman) ". "}.lst-kix_z5vjwkd6ap1-3>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-3,decimal) ". "}ol.lst-kix_z5vjwkd6ap1-3.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-3 0}ol.lst-kix_z5vjwkd6ap1-0.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-0 0}.lst-kix_z5vjwkd6ap1-0>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-0}.lst-kix_z5vjwkd6ap1-3>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-3}.lst-kix_z5vjwkd6ap1-6>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-6}.lst-kix_z5vjwkd6ap1-1>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-1}ol.lst-kix_z5vjwkd6ap1-1.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-1 0}ol.lst-kix_z5vjwkd6ap1-4.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-4 0}.lst-kix_g6r1p2efkon0-4>li:before{content:"\0025cb  "}.lst-kix_g6r1p2efkon0-5>li:before{content:"\0025a0  "}ol.lst-kix_z5vjwkd6ap1-5.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-5 0}.lst-kix_z5vjwkd6ap1-2>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-2}.lst-kix_g6r1p2efkon0-1>li:before{content:"\0025cb  "}.lst-kix_g6r1p2efkon0-2>li:before{content:"\0025a0  "}.lst-kix_g6r1p2efkon0-3>li:before{content:"\0025cf  "}ol.lst-kix_z5vjwkd6ap1-2.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-2 0}ol.lst-kix_z5vjwkd6ap1-0{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-8.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-8 0}ol.lst-kix_z5vjwkd6ap1-1{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-2{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-3{list-style-type:none}.lst-kix_z5vjwkd6ap1-7>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-7}ol.lst-kix_z5vjwkd6ap1-4{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-5{list-style-type:none}.lst-kix_g6r1p2efkon0-8>li:before{content:"\0025a0  "}.lst-kix_g6r1p2efkon0-6>li:before{content:"\0025cf  "}.lst-kix_g6r1p2efkon0-7>li:before{content:"\0025cb  "}ul.lst-kix_g6r1p2efkon0-2{list-style-type:none}ul.lst-kix_g6r1p2efkon0-3{list-style-type:none}ul.lst-kix_g6r1p2efkon0-4{list-style-type:none}ul.lst-kix_g6r1p2efkon0-5{list-style-type:none}ul.lst-kix_g6r1p2efkon0-6{list-style-type:none}ul.lst-kix_g6r1p2efkon0-7{list-style-type:none}ul.lst-kix_g6r1p2efkon0-8{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-6{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-7{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-8{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-6.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-6 0}ul.lst-kix_g6r1p2efkon0-0{list-style-type:none}ul.lst-kix_g6r1p2efkon0-1{list-style-type:none}.lst-kix_z5vjwkd6ap1-8>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-8}.lst-kix_g6r1p2efkon0-0>li:before{content:"\0025cf  "}.lst-kix_z5vjwkd6ap1-5>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-5}ol{margin:0;padding:0}table td,table th{padding:0}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c21{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#ffffff;border-bottom-style:solid}.c14{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:156pt;border-top-color:#000000;border-bottom-style:solid}.c4{-webkit-text-decoration-skip:none;color:#000000;font-weight:700;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:14pt;font-family:"Arial";font-style:normal}.c24{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:18pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c23{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c0{padding-top:0pt;text-indent:36pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c22{border-spacing:0;border-collapse:collapse;margin-right:auto}.c16{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c13{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c1{padding:0;margin:0}.c17{color:inherit;text-decoration:inherit}.c18{padding-left:0pt}.c15{font-size:12pt}.c8{height:0pt}.c12{margin-left:36pt}.c7{height:11pt}.c20{font-weight:700}.c19{margin-left:72pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c13"><p class="c10"><span class="c20 c24">Implementation of Classification Algorithms Using Apache Spark</span></p><p class="c3 c7"><span class="c6"></span></p><a id="t.8868bd848e7e63f047d134bbf0ac64f31427d11c"></a><a id="t.0"></a><table class="c22"><tbody><tr class="c8"><td class="c21" colspan="1" rowspan="1"><p class="c11"><span class="c6">Anagha Sarmalkar (801077504)</span></p></td><td class="c21" colspan="1" rowspan="1"><p class="c11"><span class="c6">Shweta Patil (801074059)</span></p></td></tr></tbody></table><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Project Overview : </span></p><p class="c0"><span class="c5">Our goal was to implement classification algorithms from scratch using Apache Spark, measuring model performance and comparing it with the model executed using Spark&rsquo;s built-in machine learning library MLlib. We have used an airline dataset for predicting whether flights will be delayed or not based on feature parameters. </span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Motivation:</span></p><p class="c0"><span class="c5">The motivation for this project was our curiosity behind the workings of machine learning algorithms. We&rsquo;ve been accustomed to using algorithms from libraries which posed like black boxes, thus gaining very little understanding of what actually goes under the hood. We designed our own data structures for implementing the algorithms, something we don&rsquo;t have the liberty of while using algorithms from libraries. The boom in Big Data from recent years has made it imperative to leverage Apache Spark&rsquo;s powerful distributed computing framework. Although implementing machine learning algorithms using distributed computing was something we never attempted, it definitely proved to be a richly rewarding experience despite being a challenge. This project has definitely helped us gain more clarity about working with large amounts of data using the powerful tools that are out there. </span></p><p class="c0"><span class="c5">In order to understand how well our algorithms perform, we decided to test their evaluation metrics using those of &nbsp;those of algorithms from Spark&rsquo;s MLlib library.</span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Dataset:</span></p><p class="c0"><span class="c15">In order to make it challenging for our algorithm, we decided to work on the dataset </span><span class="c15 c20">&lsquo;2015 Flight Delays and Cancellations&rsquo;</span><span class="c5">[1]. This dataset is collected from the U.S. Department of Transportation&rsquo;s (DOT) Bureau of Transportation Statistics which contains information of flights in the year 2015, with respect to airline carrier, original airport, destination airport, distance traveled by the flight, time spent, departure delay time, arrival delay time, etc.</span></p><p class="c0"><span class="c5">This dataset is significantly large (more than 1 million rows, and 31 features), which makes it ideal for understanding the might of PySpark&rsquo;s distributed computing over Big Data. The rich feature set provided a good exercise in creating pipelines of features and tie the stages together.</span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Algorithms and Techniques implemented:</span></p><p class="c0"><span class="c5">Apache Spark is an open source cluster computing framework which has been built around speed, ease of use and streaming analytics. Python is a high level programming language which provides a wide range of libraries majorly used for Machine Learning and real time data analytics. This makes Pyspark, which is a Python API for Spark, harness the simplicity of Python and the high computing power of &nbsp;Apache Spark to process Big Data.</span></p><p class="c0"><span class="c5">We implemented Logistic Regression with Gradient Descent using PySpark. We used Pipelines to tie the stages of categorical and numerical feature encoding transformations. A pipeline chains multiple Transformations and Estimators together to specify an ML workflow.</span></p><p class="c0"><span class="c5">We unfortunately could not implement another algorithm due to time constraints.</span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Implementation </span></p><p class="c3"><span class="c5">We have followed this approach:</span></p><ul class="c1 lst-kix_g6r1p2efkon0-0 start"><li class="c3 c18 c12"><span class="c5">Exploratory Data Analysis and Feature Engineering</span></li></ul><p class="c0 c12"><span class="c5">We prototyped our algorithm on a small dataset first and gradually upscaled the number of records, till we ran out of time to submit the project. Presently, we have tested our algorithm on 100,000 rows which were sampled randomly from the main dataset. We used the following features for our project: </span></p><p class="c0"><span class="c5">Input Features:</span></p><p class="c3 c12"><span class="c5">MONTH, DAY_OF_WEEK, AIRLINE, ORIGIN_AIRPORT, DESTINATION_AIRPORT, SCHEDULED_DEPARTURE, DEPARTURE_TIME, DEPARTURE_DELAY, TAXI_OUT, WHEELS_OFF, SCHEDULED_TIME, ELAPSED_TIME, AIR_TIME, DISTANCE, WHEELS_ON, TAXI_IN, SCHEDULED_ARRIVAL, and ARRIVAL_TIME</span></p><p class="c3 c12"><span class="c5">Output Label:</span></p><p class="c3 c12"><span class="c5">ARRIVAL_DELAY</span></p><p class="c3 c12 c7"><span class="c5"></span></p><p class="c0"><span class="c5">We have selected the features for positive correlation values.</span></p><p class="c0 c7"><span class="c5"></span></p><p class="c3"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 613.33px;"><img alt="" src="images/image4.jpg" style="width: 624.00px; height: 613.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c12 c7"><span class="c5"></span></p><p class="c0 c7"><span class="c5"></span></p><ul class="c1 lst-kix_g6r1p2efkon0-0"><li class="c3 c18 c12"><span class="c5">Data preprocessing:</span></li></ul><ul class="c1 lst-kix_g6r1p2efkon0-1 start"><li class="c3 c18 c19"><span class="c5">Cleaning the data for null values and reduced the features.</span></li><li class="c3 c18 c19"><span class="c5">mputed labels for &lsquo;ARRIVAL_DELAY&rsquo; delay where values greater than 0 are labelled as &ldquo;YES&rdquo; signifying delay and values less than or equal to &ldquo;NO&rdquo; signifying no delay.</span></li><li class="c3 c18 c19"><span class="c5">The categorical columns are then encoded using One Hot Encoder and added to stages. The numerical columns are encoded and assembled using VectorAssembler. </span></li><li class="c3 c18 c19"><span class="c5">These stages added along with the assembler are then inputted to the Pipeline which chains multiple transformations and estimations together.</span></li><li class="c3 c18 c19"><span class="c5">The data is now in the form of &nbsp;a PySpark dataframe with features combined in a vector in features column and labels in a label column. We have added an index column to ensure that the features and the labels are tied to the same index. This helped us during evaluating metrics.</span></li><li class="c3 c18 c19"><span class="c5">Training and Test sets are created by splitting this dataframe randomly in the ratio 7:3</span></li></ul><ul class="c1 lst-kix_g6r1p2efkon0-0"><li class="c3 c12 c18"><span class="c5">Implementing Logistic Regression:</span></li></ul><ul class="c1 lst-kix_g6r1p2efkon0-1 start"><li class="c3 c18 c19"><span class="c5">In order to aid data flow, we persisted all the training and test rdds and unpersisted them at the end of the code.</span></li><li class="c3 c18 c19"><span class="c5">We implemented Logistic Regression with Gradient Descent. The weights and the bias was initially set to 0. Here a pair of input vector and output label (Training) was passed to the functions to calculate the loss function (weight and bias component). These components are combined together and added to be deducted from the initialized weights and bias to update them. This goes on for n iterations.</span></li><li class="c3 c18 c19"><span class="c5">The model is then tested for the test set and also for the Logistic Regression in MLlib for n iterations.</span></li></ul><p class="c3 c12 c7"><span class="c5"></span></p><p class="c0 c7"><span class="c23"></span></p><p class="c3"><span class="c4">Results : </span></p><p class="c3"><span class="c6">Logistic Regression (For 15000 records and 500 iterations)</span></p><p class="c3 c7"><span class="c5"></span></p><a id="t.968e3e9ca5f10c234ef0eb55fec9f980d3353a74"></a><a id="t.1"></a><table class="c22"><tbody><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c6">Custom Logistic Regression model statistics</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c6">MLib Logistic Regression model statistics</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Accuracy : 0.6459</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Accuracy : 0.8533</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Precision : 0.0366</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Precision : 0.8593</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Recall : 0.5333</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Recall : 0.9185</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">F-measure : 0.0675</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">F-measure : 0.8879</span></p></td></tr></tbody></table><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c15">We have plotted graphs of results of custom-built Logistic Regression model as follows - </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 606.00px; height: 347.50px;"><img alt="" src="images/image1.jpg" style="width: 606.00px; height: 347.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image2.jpg" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c6"></span></p><p class="c3 c7"><span class="c6"></span></p><p class="c3 c7"><span class="c6"></span></p><p class="c3"><span class="c6">Logistic Regression (For 100000 records and 100 iterations)</span></p><p class="c3 c7"><span class="c5"></span></p><a id="t.764fba859f29bd1fa1d782e7dcdbf6112b85e36f"></a><a id="t.2"></a><table class="c22"><tbody><tr class="c8"><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c6">Custom Logistic Regression model statistics</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c6">MLib Logistic Regression model statistics</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c6">MLib Random Forest model statistics</span></p></td></tr><tr class="c8"><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Accuracy : 0.3639</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Accuracy : 0.9903</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Accuracy : 0.8148</span></p></td></tr><tr class="c8"><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Precision : 0.9870</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Precision : 0.8593</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Precision : 0.7862</span></p></td></tr><tr class="c8"><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Recall : &nbsp;0.3628</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Recall : 0.9951</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">Recall : 0.9701</span></p></td></tr><tr class="c8"><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">F-measure : &nbsp;0.5306</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">F-measure : 0.9924</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c2"><span class="c5">F-measure : 0.8685</span></p></td></tr></tbody></table><p class="c3 c7"><span class="c6"></span></p><p class="c3 c7"><span class="c6"></span></p><p class="c3"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 641.00px; height: 342.50px;"><img alt="" src="images/image5.jpg" style="width: 641.00px; height: 342.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 301.33px;"><img alt="" src="images/image3.jpg" style="width: 624.00px; height: 301.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Accomplishment of aspects in will do, likely will do, and would ideally like to do items:</span></p><p class="c0"><span class="c5">We accomplished implementing Logistic regression from scratch. We however did not have enough time to implement another algorithm. We instead implemented Random Forest using MLlib.</span></p><p class="c0"><span class="c5">We wish we could work more on our algorithm to get the metrics closer to that of the library. They are comparable however.</span></p><p class="c0"><span class="c5">We have not implemented any more classification algorithms.</span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">Division of responsibility</span></p><p class="c3 c7"><span class="c5"></span></p><a id="t.ca1bd6cd45fa5f532e62be7852d1cc3de1cd28c1"></a><a id="t.3"></a><table class="c22"><tbody><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c11"><span class="c5">Team Member Name</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c11"><span class="c5">Task</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Anagha Sarmalkar (801077504)</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Data Preprocessing, Feature Engineering,implementing Logistic Regression, and Naive</span></p></td></tr><tr class="c8"><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Shweta Patil ((801074059) </span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c2"><span class="c5">Model Evaluations, comparison with</span></p><p class="c2"><span class="c5">algorithms in MLlib,Webpage</span></p><p class="c2 c7"><span class="c5"></span></p></td></tr></tbody></table><p class="c3 c7"><span class="c5"></span></p><p class="c3 c7"><span class="c5"></span></p><p class="c3"><span class="c4">References</span></p><p class="c3"><span class="c15">[1] 2015 Flight Delays and Cancellations </span><span class="c16 c15"><a class="c17" href="https://www.google.com/url?q=https://www.kaggle.com/usdot/flight-delays&amp;sa=D&amp;ust=1575525164995000">https://www.kaggle.com/usdot/flight-delays</a></span></p><p class="c3"><span class="c15">[2] </span><span class="c16 c15"><a class="c17" href="https://www.google.com/url?q=https://docs.databricks.com/&amp;sa=D&amp;ust=1575525164996000">https://docs.databricks.com/</a></span></p><p class="c3"><span class="c15">[3] </span><span class="c15 c16"><a class="c17" href="https://www.google.com/url?q=https://spark.apache.org/docs/latest/api/python/index.html&amp;sa=D&amp;ust=1575525164996000">https://spark.apache.org/docs/latest/api/python/index.html</a></span></p></body></html>