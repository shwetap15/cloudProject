<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol.lst-kix_z5vjwkd6ap1-5.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-5 0}.lst-kix_z5vjwkd6ap1-8>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-8,lower-roman) ". "}.lst-kix_z5vjwkd6ap1-7>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-7,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-2>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-2}.lst-kix_z5vjwkd6ap1-5>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-5,lower-roman) ". "}.lst-kix_z5vjwkd6ap1-4>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-4,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-6>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-6,decimal) ". "}ol.lst-kix_z5vjwkd6ap1-7.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-7 0}ol.lst-kix_z5vjwkd6ap1-2.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-2 0}.lst-kix_z5vjwkd6ap1-1>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-1,lower-latin) ". "}.lst-kix_z5vjwkd6ap1-4>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-4}.lst-kix_z5vjwkd6ap1-0>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-0,decimal) ". "}ol.lst-kix_z5vjwkd6ap1-0{list-style-type:none}.lst-kix_z5vjwkd6ap1-2>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-2,lower-roman) ". "}ol.lst-kix_z5vjwkd6ap1-8.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-8 0}ol.lst-kix_z5vjwkd6ap1-1{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-2{list-style-type:none}.lst-kix_z5vjwkd6ap1-3>li:before{content:"" counter(lst-ctn-kix_z5vjwkd6ap1-3,decimal) ". "}ol.lst-kix_z5vjwkd6ap1-3.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-3 0}ol.lst-kix_z5vjwkd6ap1-3{list-style-type:none}.lst-kix_z5vjwkd6ap1-7>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-7}ol.lst-kix_z5vjwkd6ap1-4{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-5{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-0.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-0 0}.lst-kix_z5vjwkd6ap1-0>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-0}.lst-kix_z5vjwkd6ap1-3>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-3}.lst-kix_z5vjwkd6ap1-6>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-6}ol.lst-kix_z5vjwkd6ap1-6{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-7{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-8{list-style-type:none}ol.lst-kix_z5vjwkd6ap1-6.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-6 0}.lst-kix_z5vjwkd6ap1-1>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-1}ol.lst-kix_z5vjwkd6ap1-1.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-1 0}.lst-kix_z5vjwkd6ap1-8>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-8}ol.lst-kix_z5vjwkd6ap1-4.start{counter-reset:lst-ctn-kix_z5vjwkd6ap1-4 0}.lst-kix_z5vjwkd6ap1-5>li{counter-increment:lst-ctn-kix_z5vjwkd6ap1-5}ol{margin:0;padding:0}table td,table th{padding:0}.c11{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c15{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#ffffff;border-top-width:1pt;border-right-width:1pt;border-left-color:#ffffff;vertical-align:top;border-right-color:#ffffff;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#ffffff;border-bottom-style:solid}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c13{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c9{color:#000000;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c2{border-spacing:0;border-collapse:collapse;margin-right:auto}.c16{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c8{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c7{font-family:"Times New Roman";color:#222222;font-weight:400}.c14{padding:0;margin:0}.c18{color:inherit;text-decoration:inherit}.c17{margin-left:36pt;padding-left:0pt}.c12{font-size:14pt}.c6{height:11pt}.c3{height:0pt}.c0{font-size:12pt}.c5{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c8"><p class="c13"><span class="c9 c5 c12">Implementation of Classification Algorithms Using Apache Spark</span></p><p class="c13 c6"><span class="c9 c12 c5"></span></p><p class="c1 c6"><span class="c4 c0"></span></p><a id="t.8868bd848e7e63f047d134bbf0ac64f31427d11c"></a><a id="t.0"></a><table class="c2"><tbody><tr class="c3"><td class="c15" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Anagha Sarmalkar (801077504)</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Shweta Patil (801074059)</span></p></td></tr></tbody></table><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Project Overview : </span></p><p class="c1"><span class="c4 c0">Our goal was to implement classification algorithms from scratch using Apache Spark, measuring model performance and comparing it with the model executed using Spark&rsquo;s built-in machine learning library MLlib. We have used an airline dataset for predicting whether flights will be delayed or not based on feature parameters. </span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Tasks and approach :</span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Steps implemented : </span></p><p class="c1"><span class="c4 c0">We have followed this approach - </span></p><ol class="c14 lst-kix_z5vjwkd6ap1-0 start" start="1"><li class="c1 c17"><span class="c4 c0">Data analysis and feature selections </span></li><li class="c1 c17"><span class="c4 c0">We have converted qualitative variables into an encoded numerical vector representation. Also, we are deciding the target variable value based on &lsquo;ARRIVAL_DELAY&rsquo; such that flight is delayed if ARRIVAL_DELAY is positive or 0 and not delayed otherwise. </span></li><li class="c1 c6 c17"><span class="c4 c0"></span></li></ol><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c0 c4">Results : </span></p><p class="c1"><span class="c9 c0 c5">Logistic Regression (For 15000 records and 500 iterations)</span></p><p class="c1 c6"><span class="c4 c0"></span></p><a id="t.c300f2985cf873939d85af96f5328a5b7170d744"></a><a id="t.1"></a><table class="c2"><tbody><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c9 c0 c5">Custom Logistic Regression model statistics</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c9 c0 c5">MLib Logistic Regression model statistics</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Accuracy : 0.6459812228074193</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Accuracy : 0.8533817521561508</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Precision : 0.0360592401802962</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Precision : 0.8593487747566297</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Recall : 0.5333333333333333</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">Recall : 0.9185504126300682</span></p></td></tr><tr class="c3"><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">F-measure : 0.0675512665862485</span></p></td><td class="c11" colspan="1" rowspan="1"><p class="c10"><span class="c4 c0">F-measure : 0.8879639264654874</span></p></td></tr></tbody></table><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c0">We have plotted graphs of results of custom-built Logistic Regression model as follows - </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 606.00px; height: 347.50px;"><img alt="" src="images/image1.jpg" style="width: 606.00px; height: 347.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image2.jpg" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0 c5 c9">Logistic Regression (For 100000 records and 100 iterations)</span></p><p class="c1 c6"><span class="c9 c0 c5"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 641.00px; height: 342.50px;"><img alt="" src="images/image4.jpg" style="width: 641.00px; height: 342.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 301.33px;"><img alt="" src="images/image3.jpg" style="width: 624.00px; height: 301.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c9 c0 c5">Dataset:</span></p><p class="c1"><span class="c4 c0">The dataset, &lsquo; 2015 Flight Delays and Cancellations&rsquo;, has been taken from</span></p><p class="c1"><span class="c4 c0">Kaggle [1]. This is a significantly large dataset with more than a million rows and 31</span></p><p class="c1"><span class="c4 c0">feature columns which would be a good means to demonstrate PySpark&rsquo;s abilities to</span></p><p class="c1"><span class="c4 c0">tame Big Data and create machine learning pipelines.</span></p><p class="c1"><span class="c4 c0">This dataset is collected from the U.S. Department of Transportation&rsquo;s (DOT)</span></p><p class="c1"><span class="c4 c0">Bureau of Transportation Statistics which contains information of flights in the year 2015</span></p><p class="c1"><span class="c4 c0">with respect to airline carrier, original airport, destination airport, distance traveled by the</span></p><p class="c1"><span class="c4 c0">flight, time spent, departure delay time, arrival delay time, etc.</span></p><p class="c1"><span class="c0">For the the purpose of classification, we have used </span><span class="c0 c7">MONTH, DAY_OF_WEEK, AIRLINE, ORIGIN_AIRPORT, DESTINATION_AIRPORT, SCHEDULED_DEPARTURE, DEPARTURE_TIME, DEPARTURE_DELAY, TAXI_OUT, WHEELS_OFF, SCHEDULED_TIME, ELAPSED_TIME, AIR_TIME, DISTANCE, WHEELS_ON, TAXI_IN, SCHEDULED_ARRIVAL, and ARRIVAL_TIME </span><span class="c0">features.</span></p><p class="c1 c6"><span class="c9 c0 c5"></span></p><p class="c1"><span class="c9 c0 c5">References:</span></p><p class="c1"><span class="c0">[1] 2015 Flight Delays and Cancellations </span><span class="c0 c16"><a class="c18" href="https://www.google.com/url?q=https://www.kaggle.com/usdot/flight-delays&amp;sa=D&amp;ust=1575519008869000">https://www.kaggle.com/usdot/flight-delays</a></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Motivation:</span></p><p class="c1"><span class="c4 c0">The motivation for this project was our curiosity behind the workings of machine learning algorithms. We&rsquo;ve been accustomed to using algorithms from libraries which posed like black boxes, thus gaining very little understanding of what actually goes under the hood. We designed our own data structures for implementing the algorithms, something we don&rsquo;t have the liberty of while using algorithms from libraries. The boom in Big Data from recent years has made it imperative to leverage Apache Spark&rsquo;s powerful distributed computing framework. Although, implementing machine learning algorithms using distributed computing was something we never attempted, it definitely proved to be a rich rewarding experience despite being a challenge. This project has definitely helped us gain more clarity about working with large amounts of data using the powerful tools that are out there. </span></p><p class="c1"><span class="c4 c0">In order to understand how well our algorithms perform, we decided to test their evaluation metrics using those of &nbsp;those of algorithms from Spark&rsquo;s MLlib library.</span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Dataset:</span></p><p class="c1"><span class="c0">In order to make it challenging for our algorithm, we decided to work on the dataset </span><span class="c0 c5">&lsquo;2015 Flight Delays and Cancellations&rsquo;</span><span class="c4 c0">. This dataset is significantly large (more than 1 million rows, and 31 features), which makes it ideal for understanding the might of PySpark&rsquo;s distributed computing over Big Data. The rich feature set provided a good exercise in creating pipelines of features and tie the stages together.</span></p><p class="c1"><span class="c4 c0">We prototyped our algorithm on a small dataset first and gradually upscaling the number of records, till we ran out of time to submit the project. Presently, we have tested our algorithm on 100,000 rows which were sampled randomly from the main dataset. We used the following features for our project:</span></p><p class="c1"><span class="c4 c0">MONTH, DAY_OF_WEEK, AIRLINE, ORIGIN_AIRPORT, DESTINATION_AIRPORT, SCHEDULED_DEPARTURE, DEPARTURE_TIME, DEPARTURE_DELAY, TAXI_OUT, WHEELS_OFF, SCHEDULED_TIME, ELAPSED_TIME, AIR_TIME, DISTANCE, WHEELS_ON, TAXI_IN, SCHEDULED_ARRIVAL, and ARRIVAL_TIME</span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">These features were selected considering the fact that they were related to the </span></p><p class="c1"><span class="c4 c0">Categorical and numerical : correlation</span></p><p class="c1 c6"><span class="c4 c0"></span></p><p class="c1"><span class="c4 c0">Algorithms and Techniques implemented:</span></p><p class="c1"><span class="c4 c0">We implemented Logistic Regression using Gradient Descent using PySpark which is a Python API for Spark.</span></p></body></html>